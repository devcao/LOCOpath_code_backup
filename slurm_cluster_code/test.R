mat = matrix(NA, nrow = 100, ncol = 4)

for (i in 1:100){

	data = dataGen(setting = 'dep', n = 100, p = 1000, beta = c(c(0,rep(1,9)),rep(0,990)), rho = 0)
	X = data$X; Y = data$Y;
	mat[i, 1] = LOCOLars.TS(ExtractLars.Path(x=X, y=Y,whichCov=1))
	mat[i, 2] = ExactPath.TS(X=X, Y=Y,which.covariate=1, multiTest=FALSE, betaNull=0)
	mat[i, 3] = LOCOLars.TS(ExtractLars.Path(x=X, y=Y,whichCov=2))
	mat[i, 4] = ExactPath.TS(X=X, Y=Y,which.covariate=2, multiTest=FALSE, betaNull=0)
	cat(i, mat[i, ], "\n")
}



LOCOLars.TS.new <- function(obj, s = 2, t = 2){
  # Calculate PATH statistic exactly  
  #
  # Args:
  # X,Y: design matrix and response vector
  # which.covariate: if is a vector, indicating which covariate we will be computing; if is a list: then do multiple testing.
  # 
  # normalize: argguments of lars 
  # betaNULL: same size and same data type with which.covariate, specify the null hypothesis H0: beta = betaNULL. 
  # Returns:
  # A list of lambda vector, original path, the LOCO path, and Test Statistic
  #
  #  
  
  M <- length(obj$union.lambda)
  
  Delta <- obj$beta.j.hat - obj$beta.hat
  
  Delta_1 <- Delta[-M, ]
  
  Delta_2 <- Delta[-1, ]
  
  print(dim(Delta_1))
  print(dim(Delta_2))

  Lambda <- diff(obj$union.lambda)
  
  equal_sign_indicator <- Delta_2 * Delta_1 < 0

  Epsilon <- 1/(s+1) * Lambda * abs( (Delta_2 ^ (s+1) - ((-1) ^ equal_sign_indicator) * Delta_1 ^ (s+1)) / (Delta_2 - Delta_1) )


  if(s == t){

    return( (sum(Epsilon, na.rm = TRUE)) ^ (1/t) )

  }else{

    return( sum(rowSums(Epsilon) ^ (t/s), na.rm = TRUE) ^ (1/t) )

  }
  
}

data = dataGen(setting = 'dep', n = 100, p = 1000, beta = c(c(0,rep(1,9)),rep(0,990)), rho = 0)
X = data$X; Y = data$Y;


obj = ExtractLars.Path(x=X, y=Y,whichCov=1)

LOCOLars.TS.new(obj)


ExactPath.TS(X=X, Y=Y,which.covariate=1, multiTest=FALSE, betaNull=0)                                                                                                                   
loco_resample(x=X, y=Y,whichCov=1)



###
data = depenDesign(n=100, p=1000, beta=c(c(0,rep(1,9)),rep(0,990)), 0)
x = data$X; y = data$Y

loco_resample(path_type = "lars", 
                         x = x, y = y, s = 2 , t = 2,
                         whichCov = 1, B = 500, 
                         betaNULL = 0, 
                         n_threads = -1)

(lapply(1:500, power.loco.engine, 
                       n = 100, p = 12, beta = c(0,1,1,0,0,0,0,0,0,0,0,0), rho = 0, 
                       s = 1, t = 1,
                       B = 500, whichCov = 1, betaNULL = 0))

all_result_l1_0 = power.loco.test(n=100, p=100, beta=c(c(0,rep(1,9)),rep(0,90)), rho=0, s=2,t=2,
                           iter = 10, B = 500,
                           whichCov=1, betaNULL=0, norm = 'L1')


pval = unlist(lapply(all_result$obj, function(obj){obj$loco_obj$pval}))
  power = c()  
  power[1] = mean(pval <= 0.2) 
  power[2] = mean(pval <= 0.1)
  power[3] = mean(pval <= 0.05)  # not as good 
  power[4] = mean(pval <= 0.01)

## old code
Path.Resample.Power(n=100, p=100, beta=c(c(0,rep(1,9)),rep(0,90)), rho = 0.5, 
					iter = 500, B = 500, setting = 'dep', which.covariate=1, 
					betaNull=0, multiTest=FALSE, parallel = TRUE, norm = "L2.squared",
					path.method='lars', beta.init='adaptive')

Path.Resample.Power(n=100, p=100, beta=c(c(0,rep(1,9)),rep(0,90)), rho = 0.5, 
					iter = 500, B = 500, setting = 'dep', which.covariate=1, 
					betaNull=0, multiTest=FALSE, parallel = TRUE, norm = "L1",
					path.method='lars', beta.init='adaptive')
###

Path.Resample.Power(n=100, p=12, beta=c(0,1,1,0,0,0,0,0,0,0,0,0), rho = 0.5, 
					iter = 500, B = 500, setting = 'dep', which.covariate=1, 
					betaNull=0, multiTest=FALSE, parallel = TRUE, norm = "L1",
					path.method='lars', beta.init='adaptive')


> all_result_l1_0$loco_power
[1] 0.248 0.130 0.076 0.076
> all_result_l1_0$old_power
[1] 0.240 0.132 0.052 0.014
> all_result_l1_0$lm_power
[1] 0.206 0.100 0.040 0.006

> all_result_l2_0$loco_power
[1] 0.210 0.112 0.058 0.054
> all_result_l2_0$old_power
[1] 0.212 0.104 0.054 0.018
> all_result_l2_0$lm_power
[1] 0.190 0.080 0.042 0.010

> all_result_l2_5$loco_power
[1] 0.264 0.148 0.066 0.064
> all_result_l2_5$old_power
[1] 0.252 0.136 0.070 0.018
> all_result_l2_5$lm_power
[1] 0.218 0.114 0.056 0.008

> all_result_l1_5$loco_power
[1] 0.244 0.118 0.060 0.058
> all_result_l1_5$old_power
[1] 0.212 0.118 0.064 0.020
> all_result_l1_5$lm_power
[1] 0.204 0.100 0.046 0.010

p = 12 rho = 0 l2
> all_result$loco_power
[1] 0.210 0.112 0.058 0.054
> all_result$lm_power
[1] 0.190 0.080 0.042 0.010
> all_result$old_power
[1] 0.212 0.104 0.054 0.018


n = 100 p = 100 rho = 0 L2
Now Computing: 500
      [,1]  [,2]  [,3]  [,4]
[1,] 0.296 0.166 0.076 0.022


n = 100 p = 100 rho = 0 L1
Now Computing: 500
      [,1]  [,2]  [,3]  [,4]
[1,] 0.258 0.138 0.062 0.006


n = 100 p = 100 rho = 0.5 L1
Now Computing: 500
      [,1]  [,2]  [,3]  [,4]
[1,] 0.254 0.148 0.084 0.022

n = 100 p = 100 rho = 0.5 L2 
0.2 0.096 0.042 0.012 ## school


n = 100 p = 12 rho = 0 L1
119 MB
Now Computing: 500
      [,1]  [,2]  [,3]  [,4]
[1,] 0.242 0.108 0.062 0.012

##
n = 100 p = 12 rho = 0.5 L1
      [,1]  [,2]  [,3]  [,4]
[1,] 0.222 0.124 0.062 0.016

L1: 0.202 0.118 0.074 0.014 ## from school

L2
] 0.206 0.11 0.062 0.016 ## from school
##
n = 100 p = 1000 L1 rho = 0

data = depenDesign(n=100, p=12, beta=c(0,1,1,0,0,0,0,0,0,0,0,0), 0)
a=Path.Resample(X = data$X, Y = data$Y, 
                which.covariate = 1, betaNull = 0, multiTest = FALSE, 
                B = 10, beta.true = c(0,1,1,0,0,0,0,0,0,0,0,0), parallel = TRUE, 
                norm = 'L2.squared', path.method = 'lars', beta.init = 'adaptive')


.libPaths("~/R"); require(LOCOpath)
source("path_related.R");source("path_resample.R");source("path_power.R");

all_result_l1_0 = power.loco.test(n=100, p=12, beta=c(0,1,1,0,0,0,0,0,0,0,0,0), rho=0, s=2,t=2,
                           iter = 500, B = 500,
                           whichCov=1, betaNULL=0, norm = 'L1')

all_result_l2_5 = power.loco.test(n=100, p=12, beta=c(0,1,1,0,0,0,0,0,0,0,0,0), rho=0.5, s=2,t=2,
                           iter = 500, B = 500,
                           whichCov=1, betaNULL=0, norm = 'L2.squared')

all_result_l1_5 = power.loco.test(n=100, p=12, beta=c(0,1,1,0,0,0,0,0,0,0,0,0), rho=0.5, s=2,t=2,
                           iter = 500, B = 500,
                           whichCov=1, betaNULL=0, norm = 'L1')




unlist(lapply(all_result$obj, function(obj){obj$loco_obj$TS})) -> loco_ts
unlist(lapply(all_result$obj, function(obj){obj$old_obj$TS})) -> old_ts


## p = 12 rho = 0 L2
> all_result$loco_pval
  [1] 0.656 0.392 0.336 0.552 0.240 0.840 0.288 0.400 0.528 0.016 0.320 0.632
 [13] 0.632 0.240 0.640 0.600 0.600 0.920 0.080 0.048 0.144 0.336 0.128 0.224
 [25] 0.680 0.176 0.792 0.144 0.464 0.344 0.648 0.128 0.256 0.032 0.032 0.488
 [37] 1.000 0.080 0.984 0.568 0.872 0.768 0.664 0.032 0.160 0.688 0.968 0.624
 [49] 0.480 0.744 0.680 0.344 0.744 0.552 0.240 0.496 0.000 0.776 0.816 0.280
 [61] 0.112 0.224 0.568 0.240 0.456 0.648 1.000 0.640 0.728 0.696 0.872 0.016
 [73] 0.632 0.048 0.576 0.064 0.096 0.200 0.632 0.936 0.168 0.416 0.160 0.112
 [85] 0.208 0.528 0.368 0.928 0.288 0.728 0.112 0.688 0.256 0.728 0.184 0.824
 [97] 0.080 0.240 0.440 0.000
> all_result$odl_pval
NULL
> all_result$old_pval
  [1] 0.586 0.390 0.358 0.538 0.298 0.844 0.304 0.410 0.552 0.002 0.354 0.560
 [13] 0.610 0.214 0.572 0.566 0.544 0.902 0.076 0.060 0.186 0.310 0.082 0.220
 [25] 0.686 0.232 0.810 0.060 0.478 0.282 0.688 0.146 0.328 0.040 0.066 0.480
 [37] 0.988 0.136 0.934 0.540 0.862 0.838 0.660 0.096 0.194 0.604 0.950 0.546
 [49] 0.426 0.770 0.756 0.354 0.784 0.558 0.314 0.400 0.002 0.746 0.832 0.210
 [61] 0.070 0.264 0.618 0.220 0.414 0.676 0.990 0.564 0.726 0.808 0.834 0.054
 [73] 0.690 0.090 0.634 0.070 0.106 0.206 0.552 0.922 0.212 0.354 0.152 0.148
 [85] 0.246 0.578 0.406 0.934 0.234 0.802 0.076 0.634 0.290 0.614 0.180 0.788
 [97] 0.082 0.180 0.368 0.010
> all_result$lm_power
[1] 0.23 0.11 0.04 0.02
> all_result$lm_pval
  [1] 0.640295372 0.493268900 0.339732458 0.600825743 0.279773886 0.858084043
  [7] 0.345878259 0.446986557 0.578555400 0.006234814 0.358644818 0.690130130
 [13] 0.582072065 0.276893963 0.608947162 0.589648825 0.644261364 0.936335783
 [19] 0.100244822 0.105654710 0.242264437 0.339112895 0.082417893 0.198699339
 [25] 0.707169347 0.226204002 0.801893260 0.056721924 0.632595595 0.519926630
 [31] 0.691695116 0.167591163 0.305623274 0.043601182 0.105309308 0.455934917
 [37] 0.987740277 0.195023336 0.941075634 0.566038913 0.872407625 0.872269712
 [43] 0.720697396 0.098668805 0.346162937 0.650560264 0.933954356 0.552718095
 [49] 0.500018037 0.768015392 0.760183213 0.435513112 0.769973722 0.588508853
 [55] 0.282352437 0.457143232 0.003818197 0.747247085 0.822844541 0.234022366
 [61] 0.056829976 0.341259979 0.621898674 0.259831545 0.398899797 0.694027273
 [67] 0.981473709 0.621531186 0.737535436 0.785908225 0.812473854 0.090431894
 [73] 0.736938791 0.151203456 0.623101429 0.083121007 0.168361177 0.222410408
 [79] 0.519043813 0.931220686 0.236608246 0.403923432 0.148277546 0.245518354
 [85] 0.305501476 0.612235047 0.480227076 0.945290301 0.169426858 0.848859084
 [91] 0.074730146 0.633484068 0.367906532 0.685610483 0.112898150 0.805602129
 [97] 0.133407412 0.234948190 0.360533010 0.010903653


 > loco_ts
  [1] 0.0217810209 0.0503242462 0.0511956363 0.0271723382 0.0652527850
  [6] 0.0037816407 0.0643901449 0.0406658733 0.0238619001 0.3388464888
 [11] 0.0512083912 0.0218947111 0.0258655806 0.0697244737 0.0251663374
 [16] 0.0249017426 0.0275329482 0.0026901221 0.1448668979 0.1807038445
 [21] 0.0904554327 0.0546488711 0.1117709304 0.0842707135 0.0155894391
 [26] 0.0718167522 0.0076648750 0.1614598352 0.0274107527 0.0814080737
 [31] 0.0128659652 0.0922828101 0.0701551575 0.1881605090 0.1338208963
 [36] 0.0382655656 0.0001274298 0.0999486637 0.0011865575 0.0295514623
 [41] 0.0045199573 0.0055733535 0.0143068630 0.1215749832 0.0852693462
 [46] 0.0180161433 0.0009946880 0.0282302073 0.0388417602 0.0102586696
 [51] 0.0103298311 0.0427492721 0.0071092389 0.0219522034 0.0534267119
 [56] 0.0417313581 0.3140707782 0.0106170872 0.0066295856 0.1008852844
 [61] 0.1521042912 0.0768528976 0.0167500432 0.0806936944 0.0364587958
 [66] 0.0148718433 0.0002138398 0.0289965325 0.0089166505 0.0070444894
 [71] 0.0069125613 0.1641795429 0.0125596202 0.1056833261 0.0207611385
 [76] 0.1377342467 0.1024384399 0.0826761604 0.0289024947 0.0015295655
 [81] 0.0806242231 0.0609873680 0.1181321340 0.1038420981 0.0776663881
 [86] 0.0203972911 0.0312627794 0.0020486774 0.1123966056 0.0065209990
 [91] 0.1047466193 0.0192391004 0.0653357389 0.0222879398o 0.0990494237
 [96] 0.0073979526 0.1185262366 0.1005793040 0.0475558755 0.2476603106
> sqrt(old_ts)
  [1] 0.0217810209 0.0503242537 0.0511956363 0.0271723383 0.0652527850
  [6] 0.0037816407 0.0643901544 0.0406658912 0.0238619001 0.3388464888
 [11] 0.0512083913 0.0218947111 0.0258655879 0.0697244737 0.0251663392
 [16] 0.0249017426 0.0275329482 0.0026901221 0.1448668981 0.1807038452
 [21] 0.0904557014 0.0546488712 0.1117709346 0.0842707620 0.0155894391
 [26] 0.0718167714 0.0076648750 0.1614598353 0.0274107530 0.0814080737
 [31] 0.0128659652 0.0922828166 0.0701551575 0.1881605090 0.1338208993
 [36] 0.0382655656 0.0001274298 0.0999486637 0.0011865575 0.0295514625
 [41] 0.0045199573 0.0055733557 0.0143068631 0.1215750411 0.0852699548
 [46] 0.0180161433 0.0009946880 0.0282302073 0.0388417602 0.0102586696
 [51] 0.0103298311 0.0427492724 0.0071092524 0.0219522214 0.0534267119
 [56] 0.0417313581 0.3140707782 0.0106170886 0.0066295856 0.1008852947
 [61] 0.1521044438 0.0768528976 0.0167500432 0.0806936944 0.0364587958
 [66] 0.0148718433 0.0002138398 0.0289966724 0.0089166505 0.0070444894
 [71] 0.0069125613 0.1641795470 0.0125596202 0.1056833261 0.0207611385
 [76] 0.1377342467 0.1024384399 0.0826761604 0.0289024947 0.0015295710
 [81] 0.0806242231 0.0609873680 0.1181321448 0.1038420993 0.0776663881
 [86] 0.0203972911 0.0312627794 0.0020486774 0.1123966056 0.0065209990
 [91] 0.1047466193 0.0192391004 0.0653357829 0.0222879398 0.0990496289
 [96] 0.0073979526 0.1185263190 0.1005793041 0.0475558755 0.2476603109


.libPaths("~/R"); require(LOCOpath)
source("path_related.R");source("path_resample.R");source("path_power.R");

all_result = power.loco.test(n=100, p=100, beta=c(c(0,rep(1,9)),rep(0,90)), rho=0, s=2,t=2,
                           iter = 100, B = 500,
                           whichCov=1, betaNULL=0, norm = 'L2.squared')


unlist(lapply(all_result$obj, function(obj){obj$loco_obj$TS})) -> loco_ts
unlist(lapply(all_result$obj, function(obj){obj$old_obj$TS})) -> old_ts

> sqrt(old_ts)
 [1] 0.50183799 0.38908828 0.38102602 0.39275142 0.47265844 0.43289906
 [7] 0.66962682 0.09967669 0.18414641 0.18393873
> loco_ts
 [1] 0.50183782 0.38908744 0.38102556 0.39275059 0.47265775 0.43289375
 [7] 0.66962664 0.09967493 0.18414515 0.18393832




  sqrt(old_ts)
  [1] 0.45435830 0.38805614 0.06260460 0.20253075 0.28260621 0.13118915
  [7] 0.07907083 0.16588827 0.23650144 0.06113331 0.17922145 0.14053854
 [13] 0.42522399 0.06542219 0.02864327 0.39595600 0.19922993 0.19297677
 [19] 0.31138186 0.24652311 0.11656550 0.98848950 0.32123570 1.31867598
 [25] 0.32456521 0.26134827 0.23844704 0.25804243 0.34971717 0.24190392
 [31] 0.12472235 0.64354308 0.35328284 0.51661472 0.18039871 0.25550069
 [37] 0.06072549 0.53217873 2.38093322 0.26648949 0.24391709 0.97175537
 [43] 0.10281740 0.38625679 0.27600741 0.15235767 0.31620932 1.07784778
 [49] 0.11921149 0.23450760 0.07255607 0.51460256 0.49809818 0.18256956
 [55] 0.53924354 0.06622982 0.09475923 0.19230887 0.14534230 0.38424587
 [61] 0.27914495 0.78069632 0.13107964 0.52328247 0.10648997 0.30285064
 [67] 1.64300415 0.21858687 0.24284554 0.47351286 0.02400589 0.31093542
 [73] 0.02296694 1.93799018 0.15744302 0.75790992 0.19788736 1.55409911
 [79] 0.17194656 0.18149244 0.19729445 0.18726296 0.20535863 0.11542776
 [85] 0.47645962 0.08815768 0.44258767 0.17039590 0.42698444 0.84461983
 [91] 0.36191882 0.68318896 0.15182223 0.41543092 0.78511622 0.33109842
 [97] 0.14003261 0.13881773 0.17550241 0.23286407
> loco_ts
  [1] 4.543581e-01 3.880559e-01 6.260357e-02 2.025288e-01 2.826051e-01
  [6] 1.311881e-01 7.906963e-02 1.658878e-01 2.365008e-01 6.113030e-02
 [11] 1.792201e-01 1.405368e-01 4.252233e-01 6.542104e-02 2.864296e-02
 [16] 3.959555e-01 1.992293e-01 1.929728e-01 3.113814e-01 2.465225e-01
 [21] 1.165652e-01 9.724690e-01 3.212351e-01 1.318676e+00 3.245651e-01
 [26] 2.613478e-01 2.384461e-01 2.580400e-01 3.497166e-01 2.419031e-01
 [31] 1.247205e-01 6.435416e-01 3.532824e-01 5.166135e-01 1.803950e-01
 [36] 2.555003e-01 6.072447e-02 5.321780e-01 2.380930e+00 2.664890e-01
 [41] 2.439166e-01 9.717514e-01 1.028170e-01 3.862561e-01 2.184116e+06
 [46] 1.523571e-01 3.162086e-01 1.077847e+00 1.192112e-01 2.345071e-01
 [51] 7.255486e-02 5.146014e-01 4.980978e-01 1.825682e-01 5.392429e-01
 [56] 6.622887e-02 9.475740e-02 1.923081e-01 1.453419e-01 3.842426e-01
 [61] 4.005932e+07 7.806931e-01 1.310792e-01 5.232820e-01 1.064888e-01
 [66] 1.947223e+05 1.643000e+00 2.185859e-01 2.428452e-01 4.735126e-01
 [71] 2.400483e-02 3.109353e-01 2.296507e-02 1.937985e+00 1.574419e-01
 [76] 7.579098e-01 1.978866e-01 1.554096e+00 1.719459e-01 3.807951e+06
 [81] 1.972941e-01 1.872626e-01 2.053581e-01 1.154252e-01 4.764595e-01
 [86] 8.815433e-02 9.808768e+06 1.703943e-01 4.269836e-01 8.446163e-01
 [91] 3.619178e-01 6.831865e-01 1.518190e-01 4.154306e-01 7.851157e-01
 [96] 3.310962e-01 1.400322e-01 1.388170e-01 1.755019e-01 2.328638e-01

 > all_result$old_pval
  [1] 0.144 0.250 0.902 0.712 0.560 0.650 0.888 0.472 0.262 0.920 0.518 0.478
 [13] 0.146 0.832 0.984 0.336 0.656 0.738 0.594 0.322 0.734 0.096 0.346 0.112
 [25] 0.240 0.336 0.598 0.428 0.124 0.396 0.900 0.102 0.542 0.042 0.792 0.606
 [37] 0.944 0.062 0.024 0.550 0.484 0.188 0.680 0.212 0.676 0.800 0.352 0.000
 [49] 0.656 0.420 0.978 0.270 0.186 0.774 0.210 0.872 0.720 0.454 0.632 0.340
 [61] 0.316 0.180 0.918 0.226 0.672 0.476 0.222 0.390 0.460 0.068 0.982 0.348
 [73] 0.990 0.026 0.676 0.006 0.418 0.012 0.522 0.652 0.474 0.700 0.650 0.700
 [85] 0.252 0.932 0.176 0.684 0.112 0.078 0.200 0.284 0.544 0.740 0.108 0.378
 [97] 0.618 0.758 0.650 0.696
> all_result$pval
  [1] 0.144 0.272 0.888 0.760 0.624 0.560 0.904 0.576 0.296 0.944 0.600 0.632
 [13] 0.256 0.904 0.968 0.320 0.600 0.776 0.592 0.480 0.776 0.112 0.312 0.160
 [25] 0.232 0.416 0.616 0.416 0.128 0.368 0.840 0.144 0.632 0.032 0.792 0.624
 [37] 0.984 0.128 0.032 0.584 0.376 0.240 0.696 0.176 0.032 0.768 0.480 0.032
 [49] 0.544 0.440 1.000 0.208 0.112 0.856 0.160 0.904 0.728 0.568 0.768 0.416
 [61] 0.016 0.160 0.880 0.168 0.712 0.000 0.256 0.368 0.400 0.048 1.000 0.048
 [73] 1.000 0.048 0.736 0.016 0.424 0.000 0.472 0.000 0.544 0.680 0.640 0.728
 [85] 0.224 0.952 0.000 0.648 0.144 0.112 0.256 0.256 0.552 0.824 0.112 0.192
 [97] 0.544 0.760 0.744 0.528


 > all_result$power
[1] 0.28 0.13 0.13 0.04
 > all_result$old_power
[1] 0.22 0.1 0.06 0.02




\begin{itemize}
    \item Zhang(2017) bad size results -> remove power curves from plots   
    \item Variable screening 
          Figure 4 -> table selecting top n-1 variables as a way to compare ISIS to our LOCO.
    \item Double check size using old codes. 
    \item FINISH PAPER
\end{itemize}




\begin{itemize}
    \item GLM: 
    \item Lars -> glmnet ? in the future, what happens to the size ? 
    \item Debug new codes. 
\end{itemize}


## find a bug: it will generate very high value sometimes! 
> old_ts
  [1] 1.5891028129 0.0117357455 0.0049580897 0.1035441735 0.0948546315
  [6] 0.0698708038 0.0113431588 0.1772735239 0.0887194414 0.3428019349
 [11] 0.0395370173 0.1445551335 0.3148198691 0.1052292044 0.3536412105
 [16] 0.0707393124 0.0172815771 0.0741057042 0.0408948367 0.1609983732
 [21] 0.0646366707 0.0870876502 0.0482690563 0.0408050198 0.2875337573
 [26] 0.0540786795 0.0144188582 0.0039587331 0.2048315022 0.0225513921
 [31] 0.0266854065 0.2200678382 0.0803525466 0.0787501375 0.3997954755
 [36] 0.1115998161 0.0433356146 0.3121072226 0.0061488950 0.0300395444
 [41] 0.0671376603 0.0143277137 0.1434746820 0.0831611251 0.0126781581
 [46] 0.0010065459 0.4824149503 0.4024956533 0.2784950427 0.0941762421
 [51] 0.0009991448 0.2582372095 0.3726709679 0.0305820884 0.1484940037
 [56] 0.0598498199 1.8197615329 0.0118858649 0.0871778001 0.2337607018
 [61] 0.0017747080 0.1056400801 0.0456704507 0.0872224390 0.1864549183
 [66] 0.0126125785 0.1966244323 0.0102503866 0.4582611360 9.9869828592
 [71] 0.2054672581 0.2917371742 0.1153545903 0.0091350282 0.0407455972
 [76] 0.3489284537 0.0007016828 0.0659520261 0.0324853620 6.6389769553
 [81] 0.9851534113 0.0480184531 0.1978066317 0.0358025780 0.0667983640
 [86] 0.1479984460 0.0051583966 0.0597778357 3.1734107939 0.0199835554
 [91] 0.4675067970 0.8903815238 0.0844343504 1.1131293644 0.5413666589
 [96] 0.4699982743 0.3892957257 0.0973742231 0.0551674876 0.2495135944
> old_ts[29]
[1] 0.2048315
> loco_ts
  [1] 1.260595e+00 1.083308e-01 7.041313e-02 3.217821e-01 3.079843e-01
  [6] 2.643279e-01 1.065007e-01 4.210380e-01 2.978567e-01 6.442300e+06
 [11] 1.988383e-01 3.802035e-01 5.610876e-01 3.243900e-01 5.946771e-01
 [16] 2.659674e-01 1.314590e-01 2.722224e-01 2.022235e-01 4.012458e-01
 [21] 2.542366e-01 2.951058e-01 2.197017e-01 2.020010e-01 5.362212e-01
 [26] 2.325477e-01 1.200762e-01 6.291689e-02 5.150788e+07 1.501709e-01
 [31] 1.633558e-01 4.691133e-01 2.834651e-01 2.806232e-01 6.322921e-01
 [36] 3.340654e-01 2.081718e-01 5.586652e-01 7.840693e-02 1.733190e-01
 [41] 2.591088e-01 1.196972e-01 3.787803e-01 2.883764e-01 1.125956e-01
 [46] 3.172446e-02 6.945603e-01 6.344254e-01 5.277256e-01 3.068768e-01
 [51] 3.160665e-02 5.081695e-01 6.104673e-01 1.748768e-01 3.853486e-01
 [56] 2.446410e-01 1.348983e+00 1.090212e-01 2.952551e-01 4.834877e-01
 [61] 4.212424e-02 3.250218e-01 2.137063e-01 2.953337e-01 4.318032e-01
 [66] 1.123020e-01 4.434234e-01 1.012425e-01 6.769487e-01 3.159031e+00
 [71] 4.532833e-01 5.401267e-01 3.396388e-01 9.557679e-02 2.018548e-01
 [76] 5.906988e-01 2.648825e-02 2.568106e-01 1.802366e-01 2.577114e+00
 [81] 9.925192e-01 2.191307e-01 4.447543e-01 1.892150e-01 2.584527e-01
 [86] 3.847051e-01 7.182145e-02 2.444949e-01 1.782935e+00 1.413622e-01
 [91] 6.837441e-01 9.435996e-01 2.905751e-01 1.055049e+00 7.357761e-01
 [96] 6.855639e-01 6.239348e-01 3.120476e-01 2.348773e-01 4.995132e-01

> all_result$old_pval
  [1] 0.132 0.874 0.902 0.374 0.436 0.302 0.614 0.070 0.640 0.218 0.574 0.246
 [13] 0.210 0.274 0.220 0.460 0.702 0.494 0.620 0.092 0.422 0.244 0.562 0.824
 [25] 0.312 0.572 0.880 0.968 0.200 0.742 0.672 0.354 0.576 0.394 0.106 0.128
 [37] 0.458 0.066 0.934 0.790 0.490 0.798 0.094 0.416 0.830 0.992 0.262 0.036
 [49] 0.518 0.364 0.992 0.326 0.542 0.896 0.480 0.320 0.026 0.958 0.544 0.090
 [61] 0.930 0.456 0.510 0.616 0.498 0.644 0.054 0.858 0.208 0.006 0.394 0.056
 [73] 0.276 0.964 0.676 0.012 0.962 0.570 0.662 0.116 0.022 0.678 0.382 0.708
 [85] 0.368 0.144 0.922 0.490 0.076 0.680 0.012 0.084 0.330 0.328 0.262 0.618
 [97] 0.212 0.434 0.424 0.200
> all_result$pval
  [1] 0.112 0.776 0.832 0.336 0.280 0.328 0.552 0.056 0.720 0.000 0.440 0.272
 [13] 0.112 0.280 0.224 0.448 0.776 0.440 0.616 0.056 0.440 0.664 0.664 0.832
 [25] 0.336 0.496 0.776 0.888 0.000 0.888 0.784 0.112 0.504 0.504 0.168 0.112
 [37] 0.664 0.112 1.000 0.664 0.280 0.776 0.056 0.336 0.944 1.000 0.504 0.000
 [49] 0.496 0.440 1.000 0.328 0.504 1.000 0.496 0.504 0.000 0.888 0.448 0.112
 [61] 0.944 0.392 0.616 0.664 0.552 0.496 0.104 0.888 0.056 0.112 0.448 0.104
 [73] 0.384 0.944 0.888 0.000 1.000 0.560 0.608 0.112 0.000 0.664 0.160 0.784
 [85] 0.280 0.168 0.944 0.280 0.112 0.496 0.000 0.056 0.328 0.336 0.280 0.496
 [97] 0.112 0.496 0.448 0.112
